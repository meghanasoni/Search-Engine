# -*- coding: utf-8 -*-
"""sentenceSegmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-wUrac6dNDV_s5lu2JCZHfGEyYQRV4kO
"""

#from util import *

# Add your import statements here
from nltk.tokenize import PunktSentenceTokenizer



class SentenceSegmentation():

	def naive(self, text):
		"""
		Sentence Segmentation using a Naive Approach

		Parameters
		----------
		arg1 : str
			A string (a bunch of sentences)

		Returns
		-------
		list
			A list of strings where each string is a single sentence
		"""

		segmentedText = []

		#Fill in code here

		string_curr=""
		text=" "+text

		for i in range(0,len(text)-3):
			string_curr +=text[i]
			if(text[i]=='.' or text[i]=='!' or text[i]=='?'):
				if(text[i+1]==' '):
					if(text[i+2].isupper()):
						stri =string_curr[1:]
						segmentedText.append(stri)
						string_curr=""



			

		string_curr += text[len(text)-3:]
		stri =string_curr[1:]
		segmentedText.append(stri)






		return segmentedText





	def punkt(self, text):

		"""
		Sentence Segmentation using the Punkt Tokenizer

		Parameters
		----------
		arg1 : str
			A string (a bunch of sentences)

		Returns
		-------
		list
			A list of strings where each strin is a single sentence
		"""

		segmentedText = None
    


		#Fill in code here
		sent_tokenizer = PunktSentenceTokenizer(text)
		segmentedText = sent_tokenizer.tokenize(text)
		
		return segmentedText

#print("segmentation done")